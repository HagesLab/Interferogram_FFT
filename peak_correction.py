# -*- coding: utf-8 -*-
"""
Created on Tue Jun 15 14:47:25 2021

@author: cfai2
"""

from interferogram_functions import prep_interferogram,  FFT_intr, import_MAP
import matplotlib.pyplot as plt
import numpy as np
from numpy import savetxt
import os

def time_to_index(time_data, time):
    return np.where(time_data <= time)[0][-1]

def find_peaks(raw_data, time_data, start_time=-1, end_time=20, 
               search_radius=5, peak_thr=1.5,peak_radius=20, peaks_known=None):
    """
    Search for peaks by identifying locations in raw_data where the data
    suddenly decreases after increasing for (search_radius) consecutive points.
    
    These locations are known as peak indices.

    Parameters
    ----------
    raw_data : np.ndarray
        1-D TRPL data array
    time_data : 1D np.ndarray
        Vector of time steps.
    start_time : float, optional
        Zero-Shifted time where peak search should begin. 
        To ensure that the initial peak is included, choose a small negative time.
        The default is -1.
    end_time : float, optional
        Zero-shifted time where peak search should stop. 
        Choose a value such that the noisy data is not included. 
        The default is 20.
    search_radius : int, optional
        Number of consecutive increasing points needed to register a peak. 
        Higher values make the search less sensitive.
        The default is 5.
    peak_thr : float, optional
        How many times larger the final value in a peak compared to the first value
        must be for the peak to be considered a peak. 
        Higher values make the search less sensitive.
        The default is 1.5.
    peak_radius : int, optional
        A peak is defined as each peak_index +/- this many indices. The default is 20.
    peaks_known : list(list(int, int, int, float)), optional
        Once a peak list is generated using this function, peak values may be updated
        according to new raw_data by passing the peak list back into this function.
        E.g. each wavelength of MAP.txt has the same peak locations but different magnitudes.

    Returns
    -------
    peaks : list(list(int, int, int, float))
        List of info for each peak - each peak stores a starting time index,
        end time index, peak location index, and peak value

    """
    
    if peaks_known is not None:
        for p, peak_info in enumerate(peaks_known):
            peak_info[3] = raw_data[peak_info[2]]
        return None
    
    else:
        start_i = time_to_index(time_data, start_time)
        end_i = time_to_index(time_data, end_time)
        
        peak_base = 0
        count = 0
        peaks = []
        for i in range(start_i, end_i):
            delta = (raw_data[i+1] - raw_data[i])
            if delta < 0:
                # Streak broken
                streak_long_enough = (count >= search_radius)
                peak_large_enough = raw_data[i] > peak_thr * peak_base
                if streak_long_enough and peak_large_enough:
                    peaks.append(i)
                count = 0
                peak_base = 0
                
            elif delta > 0:
                if count == 0: peak_base = raw_data[i]
                # Continue streak
                count += 1
        
        for p, peak in enumerate(peaks):
            peaks[p] = [peak - peak_radius, peak + 10*peak_radius, peak, raw_data[peak]]
        return peaks

def subtract_peaks(raw_data, peaks, reduce=[0.55, 0.90]):
    """
    Remove extraneous peaks from raw_data using information contained in peaks list.

    Parameters
    ----------
    raw_data : np.ndarray
        1-D TRPL data array
    peaks : list
        Peak info list generated by find_peaks().
    reduce : list(floats), optional
        List of reduction factors. One factor is consumed for each extraneous peak.
        Reduction factors default to 0.9 (i.e. initial peak will scale down to 90% of
                                          extraneous peak and then be subtracted from
                                          that extraneous peak)
        once all provided factors have been consumed.
        The default is [0.55, 0.90].

    Returns
    -------
    None.

    """
    largest_peak = [-1,-1,-1,-1]
    for peak_info in peaks:
        if peak_info[3] > largest_peak[3]:
            largest_peak = peak_info
            
    if (largest_peak != peaks[0]):
        print("WARNING: largest peak is not first; start_time for find_peak() may be too low")
            
    largest_peak_values = raw_data[largest_peak[0]:largest_peak[1]]
    for i, peak_info in enumerate(peaks[1:]):
        try:
            r = reduce[i]
        except IndexError:
            r = 0.9
        raw_data[peak_info[0]:peak_info[1]] -= largest_peak_values * (r * raw_data[peak_info[2]] / largest_peak[3])

    return

if __name__ == "__main__":
    path = r"C:\Users\cfai2\Documents\src\Interferogram_FFT\20210615\105836"
    
    # Start with this as FALSE to tune peak correction using integralTRPL
    # Switch to TRUE to generate a new MAP.txt once peaks have been identified
    save_corrected_map = False
    
    # Need to background subtract first
    BKGsub = True           
    bkg_limit = -3
    TRPLmin_OM = 1e-6
    
    # Optional: set to FALSE to hide this plot when no longer needed
    plot_BKGsub = True
    
    pos_data, time_data, map_data = import_MAP(path)
    
    #Background Subtract
    t_max = time_data[np.array(np.where(np.mean(map_data,axis=0)==np.max(np.mean(map_data,axis=0)))[0],dtype="int")]
    time_data=time_data-t_max
    BKGrange = np.array([time_data[0],bkg_limit],dtype='float')  #ns
    if BKGsub:
        index = [(np.abs(time_data-np.min(BKGrange))).argmin(),(np.abs(time_data-np.max(BKGrange))).argmin()]
        BKGval = np.mean(map_data[:,np.min(index):np.max(index)],axis=1)
        map_data = map_data - np.reshape(BKGval, (len(BKGval), 1))
        
    #Plot Wavelength Averaged decay to determine time range for background subtraction
    if plot_BKGsub:
        plt.figure(3, dpi=120)
        plt.plot(time_data,np.mean(map_data,axis=0))
        plt.axvspan(np.min(BKGrange),np.max(BKGrange),facecolor='r',alpha=0.2)
        plt.xlim(right=2)
        #plt.xlabel('Time / ns')
        #plt.ylabel('Counts / a.u.')
        plt.yscale('log')
        
    integralTRPL = np.sum(map_data,axis=0)
    peaks = find_peaks(integralTRPL, time_data)
        
    #Plot Full TRPL
    plt.figure(4, dpi=120)
    plt.plot(time_data,integralTRPL)
    plt.ylim(np.max(integralTRPL)*TRPLmin_OM,2*np.max(integralTRPL))
    #plt.xlabel('Time / ns')
    #plt.ylabel('Counts / a.u.')
    #plt.title("Integral TRPL")
    plt.yscale('log')
    
    print("Found peaks: ", peaks)
    plt.figure(4)
    for peak in peaks:
        plt.plot(time_data[peak[0]:peak[1]], integralTRPL[peak[0]:peak[1]])
        
    reduce_factors = [0.55]
    subtract_peaks(integralTRPL, peaks, reduce=reduce_factors)
    
    plt.figure(6, dpi=120)
    plt.title("Peak Subtracted")
    plt.yscale('log')
    plt.ylim(np.max(integralTRPL)*TRPLmin_OM,2*np.max(integralTRPL))
    plt.plot(time_data, integralTRPL)
    
    if save_corrected_map:
        for wavelength in map_data:
            find_peaks(wavelength, time_data, peaks_known=peaks)
            subtract_peaks(wavelength, peaks, reduce=reduce_factors)
        
        np.savetxt(path+r"\MAP_corrected.txt", map_data, delimiter="\t")